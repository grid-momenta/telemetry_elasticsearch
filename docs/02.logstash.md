# Logstash

## 01 docker compose

File: docker-compose.yaml

```dockerfile
version: '3.8'

services:
  logstash:
    build:
      context: compose/logstash
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: te_logstash
    volumes:
      - ./compose/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./compose/logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5000:5000/tcp"
      - "5044:5044/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - telemetry_elasticsearch
    depends_on:
      - elasticsearch

networks:
  telemetry_elasticsearch:
    driver: bridge

volumes:
  elasticsearch:
```

### Arguments

- ELK_VERSION: For common elk version

### NB

- elasticsearch service is omitted here

## 02 docker file

File: compose/logstash/Dockerfile

```dockerfile
ARG ELK_VERSION

FROM docker.elastic.co/logstash/logstash:${ELK_VERSION}

RUN logstash-plugin install logstash-filter-json
```

## 03 elasticsearch config

File: compose/logstash/config/logstash.yml

```yaml
http.host: "0.0.0.0"
xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch:9200" ]

xpack.monitoring.enabled: true
xpack.monitoring.elasticsearch.username: elastic
xpack.monitoring.elasticsearch.password: "10091986"
```

### NB

- hosts is an array of elasticsearch containers
- username and password were set in elasticsearch service

## 04 pipeline config

File: compose/logstash/pipeline/logstash.conf

```text
input {
	tcp {
		port => 5000
	}
}

output {
	elasticsearch {
		hosts => ["elasticsearch:9200"]
		user => "elastic"
		password => "10091986"
		index => "logstash-te-%{+YYYY.MM.dd}"
	}
}
```

### NB

- In input, we declare tcp port 5000 according to logstash service
- In output, in elasticsearch output, we target same hosts as logstash.yml
- Here index is for elasticsearch logging and formatted as new one for every day (ex. logstash-te-2022.07.28)

## 05 entry logstash logging

After running all services we can log data:

```shell
telnet localhost 5000
```

Here **localhost** is logstash host and **5000** is logstash port.

## 06 check logging

We can check the log entries by curl or postman:

```shell
# Check indices
curl -X GET --user <elasticsearch_user>:<elasticsearch_password> <elasticsearch_host>:<elasticsearch_port>/_cat/indices

# For example
curl -X GET --user elastic:10091986 localhost:9200/_cat/indices
```


```shell
# Check index entries
curl -X GET --user <elasticsearch_user>:<elasticsearch_password> <elasticsearch_host>:<elasticsearch_port>/<index>/_search

# For example
curl -X GET --user elastic:10091986 localhost:9200/logstash-te-2022.07.28/_search
```
